version: "3.3"

#  This "singlebox" stack will use LOCAL storage and expects to be deployed to
#  a single Docker swarm host so that the volumes will always be available on
#  that host. etcd, Portworx storage, and firewall management are not performed
#  in this deployment, although you can still use the firewall playbook on EL7
#  (at this time) hosts running iptables. If you need to run on an existing
#  swarm of multiple hosts, we suggest you modify docker-compose-singlebox.yml
#  and place the appropriate Docker node label contraints to pin services with
#  volumes to their respective local volume hosts.
#
#  This stack should deploy to any machine capable of running Docker swarm, and
#  can be used to evaluate or even operate the DevOps stack tools, or possibly
#  as a POC before building out further.


#NETDATA
#  You'll need to install NetData on your host for Prometheus and Grafana.
#  singlebox stack has been tested on CentOS7 and macOS.
#  See https://github.com/netdata/netdata/wiki/Installation for futher
#  assistance installing NetData on your OS.


#CERTIFICATES
#  You can optionally install your own certificates into Caddy by consulting
#  ./caddy/caddycerts/README.md and manually uncommenting the related lines
#  in this file pertaining to caddy_cert and caddy_key. You'll need to add
#  CADDY_URL='*.example.com' or CADDY_URL='fqdn.example.com' and also 
#  CADDY_CERT='/etc/caddycerts/cert.pem' and CADDY_KEY='/etc/caddycerts/key.pem'
#
#  Insert CADDY_URL, CADDY_CERT, and CADDY_KEY ahead of ADMIN_PASSWORD below.
#
#  You can instead use Let's Encrypt certificates by adding
#  CADDY_URL='*.example.com' or CADDY_URL='fqdn.example.com' and also
#  CADDY_CERT='user@example.com' both ahead of ADMIN_PASSWORD below.


#macOS
#  With brew installed, install NetData with 'brew install netdata'.
#  You'll then need to edit:
#
#    /usr/local/etc/netdata/netdata.conf
#
#  and change 'localhost' to '*' to allow NetData to bind the macOS IP. Then:
#
#    'brew services restart netdata' to restart NetData with the new setting.
#
#  You'll also need to expose Docker 'experimental' metrics on default port
#  9323, see this URL for instructions on macOS:
#
#    https://www.brianchristner.io/how-to-monitor-docker-for-mac-windows/
#  
#  You might care to also update the Docker storage-driver from older "aufs" to
#  "overlay2" before clicking "Apply & Restart".


#INSTALL
#  All singlebox users will need to edit the 2 files below and add your host's
#  IP address; replace all occurances of the 10.0.13.2 IP with your host IP so
#  that Caddy and Prometheus can access your Docker and NetData installations:
#
#    ./caddy/Caddyfile-singlebox
#    ./prometheus/conf/prometheus-singlebox.yml

#  Finally, after you've initalized swarm mode on the single Docker host or
#  macOS with 'docker swarm init', and your host responds to 'docker node ls',
#  you won't run any of the ansible playbooks from swarmstack, instead just
#  deploy this pre-configured docker-compose-singlebox.yml stack with, noting
#  to optionally add CADDY_CERT, CADDY_KEY, and CADDY_URL as above if needed.

#    ADMIN_PASSWORD='changeme!42' docker stack deploy -c docker-compose-singlebox.yml swarmstack

#  You should then be able to surf to http://127.0.0.1 and access each tool as
#  'admin' and the ADMIN_PASSWORD you've set.

#UNINSTALL
#  docker stack rm swarmstack && docker volume prune

#RE-INITIALIZE A SERVICE
#  docker stack rm swarmstack && docker volume rm swarmstack_grafana &&
#  (deploy as above ADMIN_PASSWORD=' CADDY_... docker stack deploy -c...)


networks:
  net:
    driver: overlay
    driver_opts:
      encrypted: "true"
    attachable: true

volumes:
    alertmanager:
    alertmanagerB:
    caddycerts:
    grafana:
    portainer_data:
    portainer_certs:
    prometheus:

configs:
  alertmanager_config:
    file: ./alertmanager/conf/alertmanager.yml

  caddy_config:
    file: ./caddy/Caddyfile-singlebox
  caddy_www:
    file: ./caddy/index-singlebox.html
#  caddy_cert:
#    file: ./caddy/caddycerts/cert.pem
#  caddy_key:
#    file: ./caddy/caddycerts/key.pem
#    file: ./caddy/caddycerts/single-combined-file.pem

  grafana_provisioning_datasources:
    file: ./grafana/datasources/prometheus.yaml
  grafana_provisioning_dashboards:
    file: ./grafana/dashboards.yml
  grafana_dashboard-cluster-nodes:
    file: ./grafana/dashboards/cluster-nodes.json
  grafana_dashboard_prometheus-2-stats:
    file: ./grafana/dashboards/prometheus-2-stats.json
  grafana_dashboard_docker-containers:
    file: ./grafana/dashboards/docker-containers.json

  prometheus-conf:
    file: ./prometheus/conf/prometheus-singlebox.yml
  prometheus-container_nodes:
    file: ./prometheus/rules/container_nodes.yml
  prometheus-docker_containers:
    file: ./prometheus/rules/docker_containers.yml

  unsee-conf:
    file: ./unsee/unsee.yaml

services:

  alertmanager:
    image: prom/alertmanager:v0.15.2
    networks:
      - net
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--cluster.listen-address=0.0.0.0:9094'
      - '--cluster.advertise-address=:9094'
      - '--cluster.peer=alertmanagerB:9094'
    configs:
      - source: alertmanager_config
        target: /etc/alertmanager/alertmanager.yml
    volumes:
      - alertmanager:/alertmanager
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  alertmanagerB:
    image: prom/alertmanager:v0.15.2
    networks:
      - net
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--cluster.listen-address=0.0.0.0:9094'
      - '--cluster.advertise-address=:9094'
      - '--cluster.peer=alertmanager:9094'
    configs:
      - source: alertmanager_config
        target: /etc/alertmanager/alertmanager.yml
    volumes:
      - alertmanagerB:/alertmanager
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  caddy:
    image: swarmstack/caddy:no-stats
    ports:
      - "80:80"
      - "443:443"
      - "3000:3000"
      - "9000:9000"
      - "9090:9090"
      - "9091:9091"
      - "9093:9093"
      - "9094:9094"
      - "9095:9093"
      - "19998:19999"
    networks:
      - net
    environment:
      - ADMIN_USER=${ADMIN_USER:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - CADDYPATH=/etc/caddycerts
      - CADDY_CERT=${CADDY_CERT:-self_signed}
      - CADDY_KEY=${CADDY_KEY:-}
      - CADDY_URL=${CADDY_URL:-}
      - PUSH_USER=${PUSH_USER:-pushuser}
      - PUSH_PASSWORD=${PUSH_PASSWORD:-pushpass}
      #- http_proxy=http://proxy.example.com:80
      #- https_proxy=https://proxy.example.com:443
      #- no_proxy=10.0.0.0/8,.example.com
    configs:
      - source: caddy_config
        target: /etc/Caddyfile
      - source: caddy_www
        target: /www/index.html
#      - source: caddy_cert
#        target: /caddy/caddycerts/cert.pem
#      - source:  caddy_key
#        target: /caddy/caddycerts/key.pem
    volumes:
      - caddycerts:/etc/caddycerts
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  cadvisor:
    image: google/cadvisor:v0.31.0
    networks:
      - net
    command: -logtostderr -docker_only
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /:/rootfs:ro
      - /var/run:/var/run
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  grafana:
    image: grafana/grafana:5.3.2
    networks:
      - net
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      #- GF_PATHS_PROVISIONING=/etc/grafana/provisioning/
      #- GF_SERVER_ROOT_URL=${GF_SERVER_ROOT_URL:-localhost}
      #- GF_SMTP_ENABLED=${GF_SMTP_ENABLED:-false}
      #- GF_SMTP_FROM_ADDRESS=${GF_SMTP_FROM_ADDRESS:-grafana@test.com}
      #- GF_SMTP_FROM_NAME=${GF_SMTP_FROM_NAME:-Grafana}
      #- GF_SMTP_HOST=${GF_SMTP_HOST:-smtp:25}
      #- GF_SMTP_USER=${GF_SMTP_USER}
      #- GF_SMTP_PASSWORD=${GF_SMTP_PASSWORD}
      #- http_proxy=http://proxy.example.com:80
      #- https_proxy=https://proxy.example.com:443
      #- no_proxy=10.0.0.0/8,.example.com
    volumes:
      - grafana:/var/lib/grafana
    configs:
      - source: grafana_dashboard-cluster-nodes
        target: /etc/grafana/dashboards/cluster-nodes.json
      - source: grafana_dashboard_docker-containers
        target: /etc/grafana/dashboards/docker-containers.json
      - source: grafana_dashboard_prometheus-2-stats
        target: /etc/grafana/dashboards/prometheus-2-stats.json
      - source: grafana_provisioning_dashboards
        target: /etc/grafana/provisioning/dashboards/dashboards.yml
      - source: grafana_provisioning_datasources
        target: /etc/grafana/provisioning/datasources/prometheus.yaml
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  portainer:
    image: portainer/portainer:1.19.2
    command: -H tcp://tasks.portainer-agent:9001 --tlsskipverify
    volumes:
      - portainer_data:/data
      - portainer_certs:/certs
    networks:
      - net
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]

  portainer-agent:
    image: portainer/agent:1.1.2
    environment:
      AGENT_CLUSTER_ADDR: tasks.portainer-agent
      # AGENT_PORT: 9001
      LOG_LEVEL: warn
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - net
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  prometheus:
    image: prom/prometheus:v2.5.0
    networks:
      - net
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention=24h'
      - '--web.enable-admin-api'
    volumes:
      - prometheus:/prometheus
    configs:
      - source: prometheus-conf
        target: /etc/prometheus/prometheus.yml
      - source: prometheus-container_nodes
        target: /etc/prometheus/container_nodes.yml
      - source: prometheus-docker_containers
        target: /etc/prometheus/docker_containers.yml
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 1024M

  pushgateway:
    image: prom/pushgateway:v0.6.0
    networks:
      - net
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  unsee:
    image: cloudflare/unsee:v0.9.2
    configs:
      - source: unsee-conf
        target: /unsee.yaml
    networks:
      - net
    environment:
      - "ALERTMANAGER_URIS=alertmanager:http://alertmanager:9093 alertmanagerB:http://alertmanagerB:9093"
    deploy:
      mode: replicated
      replicas: 1
